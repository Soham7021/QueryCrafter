{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-21T21:09:28.728345Z","iopub.status.busy":"2024-07-21T21:09:28.727549Z","iopub.status.idle":"2024-07-21T21:09:29.714352Z","shell.execute_reply":"2024-07-21T21:09:29.713498Z","shell.execute_reply.started":"2024-07-21T21:09:28.728311Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:09:29.716855Z","iopub.status.busy":"2024-07-21T21:09:29.716097Z","iopub.status.idle":"2024-07-21T21:09:59.658489Z","shell.execute_reply":"2024-07-21T21:09:59.657556Z","shell.execute_reply.started":"2024-07-21T21:09:29.716821Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kaggle-environments 1.14.15 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:09:59.660135Z","iopub.status.busy":"2024-07-21T21:09:59.659825Z","iopub.status.idle":"2024-07-21T21:10:12.307043Z","shell.execute_reply":"2024-07-21T21:10:12.305827Z","shell.execute_reply.started":"2024-07-21T21:09:59.660104Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.26.4)\n"]}],"source":["!pip install scipy"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:12.311369Z","iopub.status.busy":"2024-07-21T21:10:12.311052Z","iopub.status.idle":"2024-07-21T21:10:32.889155Z","shell.execute_reply":"2024-07-21T21:10:32.888159Z","shell.execute_reply.started":"2024-07-21T21:10:12.311336Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-21 21:10:20.231833: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-21 21:10:20.231960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-21 21:10:20.362022: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, PeftModel\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:32.890693Z","iopub.status.busy":"2024-07-21T21:10:32.890415Z","iopub.status.idle":"2024-07-21T21:10:32.900498Z","shell.execute_reply":"2024-07-21T21:10:32.899551Z","shell.execute_reply.started":"2024-07-21T21:10:32.890669Z"},"trusted":true},"outputs":[],"source":["# The model that you want to train from the Hugging Face hub\n","model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n","\n","# The instruction dataset to use\n","dataset_name = \"Clinton/texttosqlv2_25000_v2\"\n","\n","# Fine-tuned model name\n","new_model = \"llama-2-7b-text-sql\"\n","\n","################################################################################\n","# QLoRA parameters\n","################################################################################\n","\n","# LoRA attention dimension\n","lora_r = 64\n","\n","# Alpha parameter for LoRA scaling\n","lora_alpha = 16\n","\n","# Dropout probability for LoRA layers\n","lora_dropout = 0.1\n","\n","\n","# bitsandbytes parameters\n","\n","\n","# Activate 4-bit precision base model loading\n","use_4bit = True\n","\n","# Compute dtype for 4-bit base models\n","bnb_4bit_compute_dtype = \"float16\"\n","\n","# Quantization type (fp4 or nf4)\n","bnb_4bit_quant_type = \"nf4\"\n","\n","# Activate nested quantization for 4-bit base models (double quantization)\n","use_nested_quant = False\n","\n","# TrainingArguments parameters\n","\n","\n","# Output directory where the model predictions and checkpoints will be stored\n","output_dir = \"./results\"\n","\n","# Number of training epochs\n","num_train_epochs = 1\n","\n","# Enable fp16/bf16 training (set bf16 to True with an A100)\n","fp16 = False\n","bf16 = False\n","\n","# Batch size per GPU for training\n","per_device_train_batch_size = 4\n","\n","# Batch size per GPU for evaluation\n","per_device_eval_batch_size = 4\n","\n","# Number of update steps to accumulate the gradients for\n","gradient_accumulation_steps = 1\n","\n","# Enable gradient checkpointing\n","gradient_checkpointing = True\n","\n","# Maximum gradient normal (gradient clipping)\n","max_grad_norm = 0.3\n","\n","# Initial learning rate (AdamW optimizer)\n","learning_rate = 2e-4\n","\n","# Weight decay to apply to all layers except bias/LayerNorm weights\n","weight_decay = 0.001\n","\n","# Optimizer to use\n","optim = \"paged_adamw_32bit\"\n","\n","# Learning rate schedule\n","lr_scheduler_type = \"cosine\"\n","\n","# Number of training steps (overrides num_train_epochs)\n","max_steps = -1\n","\n","# Ratio of steps for a linear warmup (from 0 to learning rate)\n","warmup_ratio = 0.03\n","\n","# Group sequences into batches with same length\n","# Saves memory and speeds up training considerably\n","group_by_length = True\n","\n","# Save checkpoint every X updates steps\n","save_steps = 0\n","\n","# Log every X updates steps\n","logging_steps = 25\n","\n","\n","# SFT parameters\n","\n","\n","# Maximum sequence length to use\n","max_seq_length = 256\n","\n","# Pack multiple short examples in the same input sequence to increase efficiency\n","packing = False\n","\n","# Load the entire model on the GPU 0\n","device_map = \"auto\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:32.902108Z","iopub.status.busy":"2024-07-21T21:10:32.901829Z","iopub.status.idle":"2024-07-21T21:10:35.796518Z","shell.execute_reply":"2024-07-21T21:10:35.795585Z","shell.execute_reply.started":"2024-07-21T21:10:32.902085Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19241d502d3a4fa797a9977c5427418f","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9485cc258e164e3c9deab71f94b150ed","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/56.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca78f6c492d2424bb7a67fcc77380991","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(dataset_name, split=\"train\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:35.798140Z","iopub.status.busy":"2024-07-21T21:10:35.797717Z","iopub.status.idle":"2024-07-21T21:10:35.807414Z","shell.execute_reply":"2024-07-21T21:10:35.806354Z","shell.execute_reply.started":"2024-07-21T21:10:35.798104Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'instruction': 'tell me the number of times he placed 4th .',\n"," 'input': 'CREATE TABLE table_204_780 (\\n    id number,\\n    \"year\" number,\\n    \"competition\" text,\\n    \"venue\" text,\\n    \"position\" text,\\n    \"notes\" text\\n)',\n"," 'output': 'SELECT COUNT(*) FROM table_204_780 WHERE \"position\" = 4',\n"," 'text': 'Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ### Instruction: tell me the number of times he placed 4th . ### Input: CREATE TABLE table_204_780 (\\n    id number,\\n    \"year\" number,\\n    \"competition\" text,\\n    \"venue\" text,\\n    \"position\" text,\\n    \"notes\" text\\n) ### Response: SELECT COUNT(*) FROM table_204_780 WHERE \"position\" = 4'}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:35.808782Z","iopub.status.busy":"2024-07-21T21:10:35.808491Z","iopub.status.idle":"2024-07-21T21:10:36.015833Z","shell.execute_reply":"2024-07-21T21:10:36.014677Z","shell.execute_reply.started":"2024-07-21T21:10:35.808757Z"},"trusted":true},"outputs":[],"source":["ds = {'inp':[]}"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:36.017333Z","iopub.status.busy":"2024-07-21T21:10:36.017006Z","iopub.status.idle":"2024-07-21T21:10:36.025265Z","shell.execute_reply":"2024-07-21T21:10:36.024452Z","shell.execute_reply.started":"2024-07-21T21:10:36.017306Z"},"trusted":true},"outputs":[],"source":["def formatting_func(row):\n","    prompt = f\"[INST]Prompt: {row['instruction']} Context: {row['input']} [/INST] {row['output']}\"\n","    ds['inp'].append(prompt)\n","    return row"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:36.028497Z","iopub.status.busy":"2024-07-21T21:10:36.028134Z","iopub.status.idle":"2024-07-21T21:10:38.666921Z","shell.execute_reply":"2024-07-21T21:10:38.666002Z","shell.execute_reply.started":"2024-07-21T21:10:36.028471Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a34858c217a42fb9691e6399a0aeaea","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = dataset.map(formatting_func)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:38.669048Z","iopub.status.busy":"2024-07-21T21:10:38.668218Z","iopub.status.idle":"2024-07-21T21:10:38.884558Z","shell.execute_reply":"2024-07-21T21:10:38.883616Z","shell.execute_reply.started":"2024-07-21T21:10:38.669010Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'inp': '[INST]Prompt: tell me the number of times he placed 4th . Context: CREATE TABLE table_204_780 (\\n    id number,\\n    \"year\" number,\\n    \"competition\" text,\\n    \"venue\" text,\\n    \"position\" text,\\n    \"notes\" text\\n) [/INST] SELECT COUNT(*) FROM table_204_780 WHERE \"position\" = 4'}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset,Dataset\n","import pandas as pd\n","df = pd.DataFrame(data=ds)\n","dataset = Dataset.from_pandas(df)\n","\n","dataset[0]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T21:10:38.886131Z","iopub.status.busy":"2024-07-21T21:10:38.885830Z","iopub.status.idle":"2024-07-22T05:07:15.808966Z","shell.execute_reply":"2024-07-22T05:07:15.807749Z","shell.execute_reply.started":"2024-07-21T21:10:38.886106Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4a5ffa6f920463195b96ceddcb4e50c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d74efd37fba44538952204f30eaac601","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f8ae0b8af5b4dff8c4419849a51d213","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"352393e132764b14b6fb72e669fd8eac","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0212914bc0404593801bf7966d15977a","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5324fd473d1416cbebc122ff88f9972","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54dbfb5c8d1d4eeebe02246077385d01","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6009814e183640aeb46e55b3dec26679","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55bff5747bb94681bc584c37f74c7f1e","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a947c669fe9f4048b36340748edb3b8e","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04dc78bfe64c49bd9f80ddc7118e2ab8","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"266fdd977dc64475ad833f6d9600840d","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02dd7ea1b56f48a7805bb03e27735208","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240721_211529-uuqacvwo</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/nimbalkarss123-d-y-patil-college-of-engineering-akurdi-pune/huggingface/runs/uuqacvwo' target=\"_blank\">upbeat-aardvark-1</a></strong> to <a href='https://wandb.ai/nimbalkarss123-d-y-patil-college-of-engineering-akurdi-pune/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/nimbalkarss123-d-y-patil-college-of-engineering-akurdi-pune/huggingface' target=\"_blank\">https://wandb.ai/nimbalkarss123-d-y-patil-college-of-engineering-akurdi-pune/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/nimbalkarss123-d-y-patil-college-of-engineering-akurdi-pune/huggingface/runs/uuqacvwo' target=\"_blank\">https://wandb.ai/nimbalkarss123-d-y-patil-college-of-engineering-akurdi-pune/huggingface/runs/uuqacvwo</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12500/12500 7:51:25, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>2.336200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>3.314600</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.973100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.120500</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>1.395900</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.145900</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>1.239400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.991400</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>1.113600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.940200</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>1.046900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.927800</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>0.973800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.869800</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>0.918500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.819300</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>0.893300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.848600</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>0.805300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.830100</td>\n","    </tr>\n","    <tr>\n","      <td>525</td>\n","      <td>0.801400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.831700</td>\n","    </tr>\n","    <tr>\n","      <td>575</td>\n","      <td>0.757500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.834000</td>\n","    </tr>\n","    <tr>\n","      <td>625</td>\n","      <td>0.727200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.808600</td>\n","    </tr>\n","    <tr>\n","      <td>675</td>\n","      <td>0.772800</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.827300</td>\n","    </tr>\n","    <tr>\n","      <td>725</td>\n","      <td>0.728000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.798900</td>\n","    </tr>\n","    <tr>\n","      <td>775</td>\n","      <td>0.661300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.805700</td>\n","    </tr>\n","    <tr>\n","      <td>825</td>\n","      <td>0.646700</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.770200</td>\n","    </tr>\n","    <tr>\n","      <td>875</td>\n","      <td>0.664600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.803400</td>\n","    </tr>\n","    <tr>\n","      <td>925</td>\n","      <td>0.640500</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.762300</td>\n","    </tr>\n","    <tr>\n","      <td>975</td>\n","      <td>0.658300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.767500</td>\n","    </tr>\n","    <tr>\n","      <td>1025</td>\n","      <td>0.686500</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.779900</td>\n","    </tr>\n","    <tr>\n","      <td>1075</td>\n","      <td>0.598200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.771300</td>\n","    </tr>\n","    <tr>\n","      <td>1125</td>\n","      <td>0.623700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.829800</td>\n","    </tr>\n","    <tr>\n","      <td>1175</td>\n","      <td>0.629200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.756400</td>\n","    </tr>\n","    <tr>\n","      <td>1225</td>\n","      <td>0.624600</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.770900</td>\n","    </tr>\n","    <tr>\n","      <td>1275</td>\n","      <td>0.530600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.719700</td>\n","    </tr>\n","    <tr>\n","      <td>1325</td>\n","      <td>0.601000</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.759000</td>\n","    </tr>\n","    <tr>\n","      <td>1375</td>\n","      <td>0.616200</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.736100</td>\n","    </tr>\n","    <tr>\n","      <td>1425</td>\n","      <td>0.613100</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.725300</td>\n","    </tr>\n","    <tr>\n","      <td>1475</td>\n","      <td>0.623700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.735400</td>\n","    </tr>\n","    <tr>\n","      <td>1525</td>\n","      <td>0.612000</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.753100</td>\n","    </tr>\n","    <tr>\n","      <td>1575</td>\n","      <td>0.574900</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.769300</td>\n","    </tr>\n","    <tr>\n","      <td>1625</td>\n","      <td>0.589300</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.746600</td>\n","    </tr>\n","    <tr>\n","      <td>1675</td>\n","      <td>0.532100</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.774100</td>\n","    </tr>\n","    <tr>\n","      <td>1725</td>\n","      <td>0.553800</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.745000</td>\n","    </tr>\n","    <tr>\n","      <td>1775</td>\n","      <td>0.514900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.715500</td>\n","    </tr>\n","    <tr>\n","      <td>1825</td>\n","      <td>0.599600</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.726900</td>\n","    </tr>\n","    <tr>\n","      <td>1875</td>\n","      <td>0.553600</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.723100</td>\n","    </tr>\n","    <tr>\n","      <td>1925</td>\n","      <td>0.509400</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.725100</td>\n","    </tr>\n","    <tr>\n","      <td>1975</td>\n","      <td>0.569700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.725700</td>\n","    </tr>\n","    <tr>\n","      <td>2025</td>\n","      <td>0.542300</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.716100</td>\n","    </tr>\n","    <tr>\n","      <td>2075</td>\n","      <td>0.503100</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.722500</td>\n","    </tr>\n","    <tr>\n","      <td>2125</td>\n","      <td>0.488300</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.743700</td>\n","    </tr>\n","    <tr>\n","      <td>2175</td>\n","      <td>0.540400</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.728000</td>\n","    </tr>\n","    <tr>\n","      <td>2225</td>\n","      <td>0.542600</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.706900</td>\n","    </tr>\n","    <tr>\n","      <td>2275</td>\n","      <td>0.421700</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.756400</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.501300</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.710100</td>\n","    </tr>\n","    <tr>\n","      <td>2375</td>\n","      <td>0.490900</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.726300</td>\n","    </tr>\n","    <tr>\n","      <td>2425</td>\n","      <td>0.427500</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.749500</td>\n","    </tr>\n","    <tr>\n","      <td>2475</td>\n","      <td>0.516200</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.703700</td>\n","    </tr>\n","    <tr>\n","      <td>2525</td>\n","      <td>0.501000</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.740200</td>\n","    </tr>\n","    <tr>\n","      <td>2575</td>\n","      <td>0.502100</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.741600</td>\n","    </tr>\n","    <tr>\n","      <td>2625</td>\n","      <td>0.498500</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.701900</td>\n","    </tr>\n","    <tr>\n","      <td>2675</td>\n","      <td>0.467300</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.706700</td>\n","    </tr>\n","    <tr>\n","      <td>2725</td>\n","      <td>0.502400</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.711000</td>\n","    </tr>\n","    <tr>\n","      <td>2775</td>\n","      <td>0.470300</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.706100</td>\n","    </tr>\n","    <tr>\n","      <td>2825</td>\n","      <td>0.500600</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.720400</td>\n","    </tr>\n","    <tr>\n","      <td>2875</td>\n","      <td>0.520300</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.709900</td>\n","    </tr>\n","    <tr>\n","      <td>2925</td>\n","      <td>0.485900</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.695100</td>\n","    </tr>\n","    <tr>\n","      <td>2975</td>\n","      <td>0.517000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.705300</td>\n","    </tr>\n","    <tr>\n","      <td>3025</td>\n","      <td>0.464500</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.751600</td>\n","    </tr>\n","    <tr>\n","      <td>3075</td>\n","      <td>0.447000</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.690700</td>\n","    </tr>\n","    <tr>\n","      <td>3125</td>\n","      <td>0.427900</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.723900</td>\n","    </tr>\n","    <tr>\n","      <td>3175</td>\n","      <td>0.458900</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.700800</td>\n","    </tr>\n","    <tr>\n","      <td>3225</td>\n","      <td>0.433000</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.720300</td>\n","    </tr>\n","    <tr>\n","      <td>3275</td>\n","      <td>0.483800</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.702200</td>\n","    </tr>\n","    <tr>\n","      <td>3325</td>\n","      <td>0.520200</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>0.695900</td>\n","    </tr>\n","    <tr>\n","      <td>3375</td>\n","      <td>0.451300</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.695800</td>\n","    </tr>\n","    <tr>\n","      <td>3425</td>\n","      <td>0.467200</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>0.701300</td>\n","    </tr>\n","    <tr>\n","      <td>3475</td>\n","      <td>0.496700</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.697300</td>\n","    </tr>\n","    <tr>\n","      <td>3525</td>\n","      <td>0.491100</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>0.662400</td>\n","    </tr>\n","    <tr>\n","      <td>3575</td>\n","      <td>0.463000</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.672700</td>\n","    </tr>\n","    <tr>\n","      <td>3625</td>\n","      <td>0.401700</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>0.645100</td>\n","    </tr>\n","    <tr>\n","      <td>3675</td>\n","      <td>0.417500</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.696100</td>\n","    </tr>\n","    <tr>\n","      <td>3725</td>\n","      <td>0.453200</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.663800</td>\n","    </tr>\n","    <tr>\n","      <td>3775</td>\n","      <td>0.493800</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.673300</td>\n","    </tr>\n","    <tr>\n","      <td>3825</td>\n","      <td>0.470100</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>0.728800</td>\n","    </tr>\n","    <tr>\n","      <td>3875</td>\n","      <td>0.467200</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.669100</td>\n","    </tr>\n","    <tr>\n","      <td>3925</td>\n","      <td>0.429700</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>0.683000</td>\n","    </tr>\n","    <tr>\n","      <td>3975</td>\n","      <td>0.451400</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.735700</td>\n","    </tr>\n","    <tr>\n","      <td>4025</td>\n","      <td>0.489600</td>\n","    </tr>\n","    <tr>\n","      <td>4050</td>\n","      <td>0.698400</td>\n","    </tr>\n","    <tr>\n","      <td>4075</td>\n","      <td>0.478300</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.668500</td>\n","    </tr>\n","    <tr>\n","      <td>4125</td>\n","      <td>0.486300</td>\n","    </tr>\n","    <tr>\n","      <td>4150</td>\n","      <td>0.697900</td>\n","    </tr>\n","    <tr>\n","      <td>4175</td>\n","      <td>0.406700</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.705200</td>\n","    </tr>\n","    <tr>\n","      <td>4225</td>\n","      <td>0.397600</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.719200</td>\n","    </tr>\n","    <tr>\n","      <td>4275</td>\n","      <td>0.471200</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.689800</td>\n","    </tr>\n","    <tr>\n","      <td>4325</td>\n","      <td>0.430400</td>\n","    </tr>\n","    <tr>\n","      <td>4350</td>\n","      <td>0.672800</td>\n","    </tr>\n","    <tr>\n","      <td>4375</td>\n","      <td>0.407900</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.657100</td>\n","    </tr>\n","    <tr>\n","      <td>4425</td>\n","      <td>0.438300</td>\n","    </tr>\n","    <tr>\n","      <td>4450</td>\n","      <td>0.663200</td>\n","    </tr>\n","    <tr>\n","      <td>4475</td>\n","      <td>0.423200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.688200</td>\n","    </tr>\n","    <tr>\n","      <td>4525</td>\n","      <td>0.404200</td>\n","    </tr>\n","    <tr>\n","      <td>4550</td>\n","      <td>0.674600</td>\n","    </tr>\n","    <tr>\n","      <td>4575</td>\n","      <td>0.456400</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.659300</td>\n","    </tr>\n","    <tr>\n","      <td>4625</td>\n","      <td>0.440700</td>\n","    </tr>\n","    <tr>\n","      <td>4650</td>\n","      <td>0.644700</td>\n","    </tr>\n","    <tr>\n","      <td>4675</td>\n","      <td>0.493100</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.683600</td>\n","    </tr>\n","    <tr>\n","      <td>4725</td>\n","      <td>0.432200</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.681700</td>\n","    </tr>\n","    <tr>\n","      <td>4775</td>\n","      <td>0.411000</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.692800</td>\n","    </tr>\n","    <tr>\n","      <td>4825</td>\n","      <td>0.415900</td>\n","    </tr>\n","    <tr>\n","      <td>4850</td>\n","      <td>0.679100</td>\n","    </tr>\n","    <tr>\n","      <td>4875</td>\n","      <td>0.461500</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.671800</td>\n","    </tr>\n","    <tr>\n","      <td>4925</td>\n","      <td>0.462300</td>\n","    </tr>\n","    <tr>\n","      <td>4950</td>\n","      <td>0.628100</td>\n","    </tr>\n","    <tr>\n","      <td>4975</td>\n","      <td>0.418200</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.667100</td>\n","    </tr>\n","    <tr>\n","      <td>5025</td>\n","      <td>0.372200</td>\n","    </tr>\n","    <tr>\n","      <td>5050</td>\n","      <td>0.659800</td>\n","    </tr>\n","    <tr>\n","      <td>5075</td>\n","      <td>0.467500</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.691200</td>\n","    </tr>\n","    <tr>\n","      <td>5125</td>\n","      <td>0.500600</td>\n","    </tr>\n","    <tr>\n","      <td>5150</td>\n","      <td>0.683800</td>\n","    </tr>\n","    <tr>\n","      <td>5175</td>\n","      <td>0.412100</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.626100</td>\n","    </tr>\n","    <tr>\n","      <td>5225</td>\n","      <td>0.385500</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.633900</td>\n","    </tr>\n","    <tr>\n","      <td>5275</td>\n","      <td>0.429200</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.670400</td>\n","    </tr>\n","    <tr>\n","      <td>5325</td>\n","      <td>0.415900</td>\n","    </tr>\n","    <tr>\n","      <td>5350</td>\n","      <td>0.665700</td>\n","    </tr>\n","    <tr>\n","      <td>5375</td>\n","      <td>0.469600</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.655600</td>\n","    </tr>\n","    <tr>\n","      <td>5425</td>\n","      <td>0.447300</td>\n","    </tr>\n","    <tr>\n","      <td>5450</td>\n","      <td>0.715600</td>\n","    </tr>\n","    <tr>\n","      <td>5475</td>\n","      <td>0.473300</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.679400</td>\n","    </tr>\n","    <tr>\n","      <td>5525</td>\n","      <td>0.463300</td>\n","    </tr>\n","    <tr>\n","      <td>5550</td>\n","      <td>0.676000</td>\n","    </tr>\n","    <tr>\n","      <td>5575</td>\n","      <td>0.461600</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.663300</td>\n","    </tr>\n","    <tr>\n","      <td>5625</td>\n","      <td>0.423200</td>\n","    </tr>\n","    <tr>\n","      <td>5650</td>\n","      <td>0.690200</td>\n","    </tr>\n","    <tr>\n","      <td>5675</td>\n","      <td>0.463100</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.661500</td>\n","    </tr>\n","    <tr>\n","      <td>5725</td>\n","      <td>0.439800</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.654600</td>\n","    </tr>\n","    <tr>\n","      <td>5775</td>\n","      <td>0.412100</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.667000</td>\n","    </tr>\n","    <tr>\n","      <td>5825</td>\n","      <td>0.429300</td>\n","    </tr>\n","    <tr>\n","      <td>5850</td>\n","      <td>0.694500</td>\n","    </tr>\n","    <tr>\n","      <td>5875</td>\n","      <td>0.417800</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.660600</td>\n","    </tr>\n","    <tr>\n","      <td>5925</td>\n","      <td>0.456900</td>\n","    </tr>\n","    <tr>\n","      <td>5950</td>\n","      <td>0.646600</td>\n","    </tr>\n","    <tr>\n","      <td>5975</td>\n","      <td>0.414800</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.663700</td>\n","    </tr>\n","    <tr>\n","      <td>6025</td>\n","      <td>0.358600</td>\n","    </tr>\n","    <tr>\n","      <td>6050</td>\n","      <td>0.655000</td>\n","    </tr>\n","    <tr>\n","      <td>6075</td>\n","      <td>0.427900</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.667800</td>\n","    </tr>\n","    <tr>\n","      <td>6125</td>\n","      <td>0.386100</td>\n","    </tr>\n","    <tr>\n","      <td>6150</td>\n","      <td>0.657700</td>\n","    </tr>\n","    <tr>\n","      <td>6175</td>\n","      <td>0.382200</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.681400</td>\n","    </tr>\n","    <tr>\n","      <td>6225</td>\n","      <td>0.430600</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.646600</td>\n","    </tr>\n","    <tr>\n","      <td>6275</td>\n","      <td>0.367100</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.607300</td>\n","    </tr>\n","    <tr>\n","      <td>6325</td>\n","      <td>0.355800</td>\n","    </tr>\n","    <tr>\n","      <td>6350</td>\n","      <td>0.637600</td>\n","    </tr>\n","    <tr>\n","      <td>6375</td>\n","      <td>0.403000</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.641200</td>\n","    </tr>\n","    <tr>\n","      <td>6425</td>\n","      <td>0.399900</td>\n","    </tr>\n","    <tr>\n","      <td>6450</td>\n","      <td>0.627500</td>\n","    </tr>\n","    <tr>\n","      <td>6475</td>\n","      <td>0.396400</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.603800</td>\n","    </tr>\n","    <tr>\n","      <td>6525</td>\n","      <td>0.381800</td>\n","    </tr>\n","    <tr>\n","      <td>6550</td>\n","      <td>0.585800</td>\n","    </tr>\n","    <tr>\n","      <td>6575</td>\n","      <td>0.412100</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.622400</td>\n","    </tr>\n","    <tr>\n","      <td>6625</td>\n","      <td>0.408700</td>\n","    </tr>\n","    <tr>\n","      <td>6650</td>\n","      <td>0.583000</td>\n","    </tr>\n","    <tr>\n","      <td>6675</td>\n","      <td>0.386800</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.597400</td>\n","    </tr>\n","    <tr>\n","      <td>6725</td>\n","      <td>0.399400</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.633500</td>\n","    </tr>\n","    <tr>\n","      <td>6775</td>\n","      <td>0.383700</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.622800</td>\n","    </tr>\n","    <tr>\n","      <td>6825</td>\n","      <td>0.418500</td>\n","    </tr>\n","    <tr>\n","      <td>6850</td>\n","      <td>0.658700</td>\n","    </tr>\n","    <tr>\n","      <td>6875</td>\n","      <td>0.401800</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.604600</td>\n","    </tr>\n","    <tr>\n","      <td>6925</td>\n","      <td>0.420000</td>\n","    </tr>\n","    <tr>\n","      <td>6950</td>\n","      <td>0.652500</td>\n","    </tr>\n","    <tr>\n","      <td>6975</td>\n","      <td>0.421800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.627700</td>\n","    </tr>\n","    <tr>\n","      <td>7025</td>\n","      <td>0.392200</td>\n","    </tr>\n","    <tr>\n","      <td>7050</td>\n","      <td>0.618100</td>\n","    </tr>\n","    <tr>\n","      <td>7075</td>\n","      <td>0.418700</td>\n","    </tr>\n","    <tr>\n","      <td>7100</td>\n","      <td>0.608900</td>\n","    </tr>\n","    <tr>\n","      <td>7125</td>\n","      <td>0.409500</td>\n","    </tr>\n","    <tr>\n","      <td>7150</td>\n","      <td>0.647000</td>\n","    </tr>\n","    <tr>\n","      <td>7175</td>\n","      <td>0.354800</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.614800</td>\n","    </tr>\n","    <tr>\n","      <td>7225</td>\n","      <td>0.390400</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.602100</td>\n","    </tr>\n","    <tr>\n","      <td>7275</td>\n","      <td>0.408900</td>\n","    </tr>\n","    <tr>\n","      <td>7300</td>\n","      <td>0.608200</td>\n","    </tr>\n","    <tr>\n","      <td>7325</td>\n","      <td>0.343000</td>\n","    </tr>\n","    <tr>\n","      <td>7350</td>\n","      <td>0.616200</td>\n","    </tr>\n","    <tr>\n","      <td>7375</td>\n","      <td>0.409900</td>\n","    </tr>\n","    <tr>\n","      <td>7400</td>\n","      <td>0.615900</td>\n","    </tr>\n","    <tr>\n","      <td>7425</td>\n","      <td>0.376300</td>\n","    </tr>\n","    <tr>\n","      <td>7450</td>\n","      <td>0.607200</td>\n","    </tr>\n","    <tr>\n","      <td>7475</td>\n","      <td>0.369900</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.624200</td>\n","    </tr>\n","    <tr>\n","      <td>7525</td>\n","      <td>0.427800</td>\n","    </tr>\n","    <tr>\n","      <td>7550</td>\n","      <td>0.628600</td>\n","    </tr>\n","    <tr>\n","      <td>7575</td>\n","      <td>0.350400</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.625400</td>\n","    </tr>\n","    <tr>\n","      <td>7625</td>\n","      <td>0.400700</td>\n","    </tr>\n","    <tr>\n","      <td>7650</td>\n","      <td>0.621500</td>\n","    </tr>\n","    <tr>\n","      <td>7675</td>\n","      <td>0.374100</td>\n","    </tr>\n","    <tr>\n","      <td>7700</td>\n","      <td>0.622100</td>\n","    </tr>\n","    <tr>\n","      <td>7725</td>\n","      <td>0.383800</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.655900</td>\n","    </tr>\n","    <tr>\n","      <td>7775</td>\n","      <td>0.384300</td>\n","    </tr>\n","    <tr>\n","      <td>7800</td>\n","      <td>0.604600</td>\n","    </tr>\n","    <tr>\n","      <td>7825</td>\n","      <td>0.344100</td>\n","    </tr>\n","    <tr>\n","      <td>7850</td>\n","      <td>0.606700</td>\n","    </tr>\n","    <tr>\n","      <td>7875</td>\n","      <td>0.419700</td>\n","    </tr>\n","    <tr>\n","      <td>7900</td>\n","      <td>0.613900</td>\n","    </tr>\n","    <tr>\n","      <td>7925</td>\n","      <td>0.385800</td>\n","    </tr>\n","    <tr>\n","      <td>7950</td>\n","      <td>0.596000</td>\n","    </tr>\n","    <tr>\n","      <td>7975</td>\n","      <td>0.388200</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.631100</td>\n","    </tr>\n","    <tr>\n","      <td>8025</td>\n","      <td>0.385100</td>\n","    </tr>\n","    <tr>\n","      <td>8050</td>\n","      <td>0.628200</td>\n","    </tr>\n","    <tr>\n","      <td>8075</td>\n","      <td>0.326500</td>\n","    </tr>\n","    <tr>\n","      <td>8100</td>\n","      <td>0.625700</td>\n","    </tr>\n","    <tr>\n","      <td>8125</td>\n","      <td>0.374700</td>\n","    </tr>\n","    <tr>\n","      <td>8150</td>\n","      <td>0.561800</td>\n","    </tr>\n","    <tr>\n","      <td>8175</td>\n","      <td>0.399000</td>\n","    </tr>\n","    <tr>\n","      <td>8200</td>\n","      <td>0.582100</td>\n","    </tr>\n","    <tr>\n","      <td>8225</td>\n","      <td>0.332200</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.646800</td>\n","    </tr>\n","    <tr>\n","      <td>8275</td>\n","      <td>0.378900</td>\n","    </tr>\n","    <tr>\n","      <td>8300</td>\n","      <td>0.562700</td>\n","    </tr>\n","    <tr>\n","      <td>8325</td>\n","      <td>0.323400</td>\n","    </tr>\n","    <tr>\n","      <td>8350</td>\n","      <td>0.623800</td>\n","    </tr>\n","    <tr>\n","      <td>8375</td>\n","      <td>0.368000</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.604200</td>\n","    </tr>\n","    <tr>\n","      <td>8425</td>\n","      <td>0.396600</td>\n","    </tr>\n","    <tr>\n","      <td>8450</td>\n","      <td>0.605000</td>\n","    </tr>\n","    <tr>\n","      <td>8475</td>\n","      <td>0.368300</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.598000</td>\n","    </tr>\n","    <tr>\n","      <td>8525</td>\n","      <td>0.370600</td>\n","    </tr>\n","    <tr>\n","      <td>8550</td>\n","      <td>0.603700</td>\n","    </tr>\n","    <tr>\n","      <td>8575</td>\n","      <td>0.345600</td>\n","    </tr>\n","    <tr>\n","      <td>8600</td>\n","      <td>0.603500</td>\n","    </tr>\n","    <tr>\n","      <td>8625</td>\n","      <td>0.375200</td>\n","    </tr>\n","    <tr>\n","      <td>8650</td>\n","      <td>0.590700</td>\n","    </tr>\n","    <tr>\n","      <td>8675</td>\n","      <td>0.398300</td>\n","    </tr>\n","    <tr>\n","      <td>8700</td>\n","      <td>0.592900</td>\n","    </tr>\n","    <tr>\n","      <td>8725</td>\n","      <td>0.297600</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.572500</td>\n","    </tr>\n","    <tr>\n","      <td>8775</td>\n","      <td>0.342800</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.608300</td>\n","    </tr>\n","    <tr>\n","      <td>8825</td>\n","      <td>0.421000</td>\n","    </tr>\n","    <tr>\n","      <td>8850</td>\n","      <td>0.650200</td>\n","    </tr>\n","    <tr>\n","      <td>8875</td>\n","      <td>0.377200</td>\n","    </tr>\n","    <tr>\n","      <td>8900</td>\n","      <td>0.616600</td>\n","    </tr>\n","    <tr>\n","      <td>8925</td>\n","      <td>0.399500</td>\n","    </tr>\n","    <tr>\n","      <td>8950</td>\n","      <td>0.625400</td>\n","    </tr>\n","    <tr>\n","      <td>8975</td>\n","      <td>0.346200</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.591200</td>\n","    </tr>\n","    <tr>\n","      <td>9025</td>\n","      <td>0.372200</td>\n","    </tr>\n","    <tr>\n","      <td>9050</td>\n","      <td>0.604100</td>\n","    </tr>\n","    <tr>\n","      <td>9075</td>\n","      <td>0.341300</td>\n","    </tr>\n","    <tr>\n","      <td>9100</td>\n","      <td>0.585800</td>\n","    </tr>\n","    <tr>\n","      <td>9125</td>\n","      <td>0.363800</td>\n","    </tr>\n","    <tr>\n","      <td>9150</td>\n","      <td>0.651500</td>\n","    </tr>\n","    <tr>\n","      <td>9175</td>\n","      <td>0.368300</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.606200</td>\n","    </tr>\n","    <tr>\n","      <td>9225</td>\n","      <td>0.360200</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.609600</td>\n","    </tr>\n","    <tr>\n","      <td>9275</td>\n","      <td>0.371400</td>\n","    </tr>\n","    <tr>\n","      <td>9300</td>\n","      <td>0.590400</td>\n","    </tr>\n","    <tr>\n","      <td>9325</td>\n","      <td>0.321500</td>\n","    </tr>\n","    <tr>\n","      <td>9350</td>\n","      <td>0.594400</td>\n","    </tr>\n","    <tr>\n","      <td>9375</td>\n","      <td>0.342500</td>\n","    </tr>\n","    <tr>\n","      <td>9400</td>\n","      <td>0.588900</td>\n","    </tr>\n","    <tr>\n","      <td>9425</td>\n","      <td>0.380500</td>\n","    </tr>\n","    <tr>\n","      <td>9450</td>\n","      <td>0.603800</td>\n","    </tr>\n","    <tr>\n","      <td>9475</td>\n","      <td>0.347900</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.630600</td>\n","    </tr>\n","    <tr>\n","      <td>9525</td>\n","      <td>0.387500</td>\n","    </tr>\n","    <tr>\n","      <td>9550</td>\n","      <td>0.620100</td>\n","    </tr>\n","    <tr>\n","      <td>9575</td>\n","      <td>0.391100</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.622200</td>\n","    </tr>\n","    <tr>\n","      <td>9625</td>\n","      <td>0.341200</td>\n","    </tr>\n","    <tr>\n","      <td>9650</td>\n","      <td>0.603600</td>\n","    </tr>\n","    <tr>\n","      <td>9675</td>\n","      <td>0.356000</td>\n","    </tr>\n","    <tr>\n","      <td>9700</td>\n","      <td>0.611500</td>\n","    </tr>\n","    <tr>\n","      <td>9725</td>\n","      <td>0.365100</td>\n","    </tr>\n","    <tr>\n","      <td>9750</td>\n","      <td>0.642000</td>\n","    </tr>\n","    <tr>\n","      <td>9775</td>\n","      <td>0.394200</td>\n","    </tr>\n","    <tr>\n","      <td>9800</td>\n","      <td>0.606700</td>\n","    </tr>\n","    <tr>\n","      <td>9825</td>\n","      <td>0.384900</td>\n","    </tr>\n","    <tr>\n","      <td>9850</td>\n","      <td>0.634200</td>\n","    </tr>\n","    <tr>\n","      <td>9875</td>\n","      <td>0.346100</td>\n","    </tr>\n","    <tr>\n","      <td>9900</td>\n","      <td>0.599200</td>\n","    </tr>\n","    <tr>\n","      <td>9925</td>\n","      <td>0.406400</td>\n","    </tr>\n","    <tr>\n","      <td>9950</td>\n","      <td>0.605900</td>\n","    </tr>\n","    <tr>\n","      <td>9975</td>\n","      <td>0.346100</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.618200</td>\n","    </tr>\n","    <tr>\n","      <td>10025</td>\n","      <td>0.366300</td>\n","    </tr>\n","    <tr>\n","      <td>10050</td>\n","      <td>0.594700</td>\n","    </tr>\n","    <tr>\n","      <td>10075</td>\n","      <td>0.339500</td>\n","    </tr>\n","    <tr>\n","      <td>10100</td>\n","      <td>0.584900</td>\n","    </tr>\n","    <tr>\n","      <td>10125</td>\n","      <td>0.384400</td>\n","    </tr>\n","    <tr>\n","      <td>10150</td>\n","      <td>0.574500</td>\n","    </tr>\n","    <tr>\n","      <td>10175</td>\n","      <td>0.392000</td>\n","    </tr>\n","    <tr>\n","      <td>10200</td>\n","      <td>0.621800</td>\n","    </tr>\n","    <tr>\n","      <td>10225</td>\n","      <td>0.334500</td>\n","    </tr>\n","    <tr>\n","      <td>10250</td>\n","      <td>0.572900</td>\n","    </tr>\n","    <tr>\n","      <td>10275</td>\n","      <td>0.406400</td>\n","    </tr>\n","    <tr>\n","      <td>10300</td>\n","      <td>0.588600</td>\n","    </tr>\n","    <tr>\n","      <td>10325</td>\n","      <td>0.445800</td>\n","    </tr>\n","    <tr>\n","      <td>10350</td>\n","      <td>0.600600</td>\n","    </tr>\n","    <tr>\n","      <td>10375</td>\n","      <td>0.418600</td>\n","    </tr>\n","    <tr>\n","      <td>10400</td>\n","      <td>0.612000</td>\n","    </tr>\n","    <tr>\n","      <td>10425</td>\n","      <td>0.348200</td>\n","    </tr>\n","    <tr>\n","      <td>10450</td>\n","      <td>0.614800</td>\n","    </tr>\n","    <tr>\n","      <td>10475</td>\n","      <td>0.377500</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.609200</td>\n","    </tr>\n","    <tr>\n","      <td>10525</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <td>10550</td>\n","      <td>0.613700</td>\n","    </tr>\n","    <tr>\n","      <td>10575</td>\n","      <td>0.353900</td>\n","    </tr>\n","    <tr>\n","      <td>10600</td>\n","      <td>0.630500</td>\n","    </tr>\n","    <tr>\n","      <td>10625</td>\n","      <td>0.373400</td>\n","    </tr>\n","    <tr>\n","      <td>10650</td>\n","      <td>0.591100</td>\n","    </tr>\n","    <tr>\n","      <td>10675</td>\n","      <td>0.306700</td>\n","    </tr>\n","    <tr>\n","      <td>10700</td>\n","      <td>0.577000</td>\n","    </tr>\n","    <tr>\n","      <td>10725</td>\n","      <td>0.357700</td>\n","    </tr>\n","    <tr>\n","      <td>10750</td>\n","      <td>0.607400</td>\n","    </tr>\n","    <tr>\n","      <td>10775</td>\n","      <td>0.348700</td>\n","    </tr>\n","    <tr>\n","      <td>10800</td>\n","      <td>0.585700</td>\n","    </tr>\n","    <tr>\n","      <td>10825</td>\n","      <td>0.390600</td>\n","    </tr>\n","    <tr>\n","      <td>10850</td>\n","      <td>0.600600</td>\n","    </tr>\n","    <tr>\n","      <td>10875</td>\n","      <td>0.352000</td>\n","    </tr>\n","    <tr>\n","      <td>10900</td>\n","      <td>0.575500</td>\n","    </tr>\n","    <tr>\n","      <td>10925</td>\n","      <td>0.352100</td>\n","    </tr>\n","    <tr>\n","      <td>10950</td>\n","      <td>0.584200</td>\n","    </tr>\n","    <tr>\n","      <td>10975</td>\n","      <td>0.358300</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.599300</td>\n","    </tr>\n","    <tr>\n","      <td>11025</td>\n","      <td>0.339700</td>\n","    </tr>\n","    <tr>\n","      <td>11050</td>\n","      <td>0.584700</td>\n","    </tr>\n","    <tr>\n","      <td>11075</td>\n","      <td>0.386900</td>\n","    </tr>\n","    <tr>\n","      <td>11100</td>\n","      <td>0.566300</td>\n","    </tr>\n","    <tr>\n","      <td>11125</td>\n","      <td>0.378200</td>\n","    </tr>\n","    <tr>\n","      <td>11150</td>\n","      <td>0.590500</td>\n","    </tr>\n","    <tr>\n","      <td>11175</td>\n","      <td>0.330000</td>\n","    </tr>\n","    <tr>\n","      <td>11200</td>\n","      <td>0.570100</td>\n","    </tr>\n","    <tr>\n","      <td>11225</td>\n","      <td>0.386000</td>\n","    </tr>\n","    <tr>\n","      <td>11250</td>\n","      <td>0.558800</td>\n","    </tr>\n","    <tr>\n","      <td>11275</td>\n","      <td>0.347900</td>\n","    </tr>\n","    <tr>\n","      <td>11300</td>\n","      <td>0.600500</td>\n","    </tr>\n","    <tr>\n","      <td>11325</td>\n","      <td>0.361100</td>\n","    </tr>\n","    <tr>\n","      <td>11350</td>\n","      <td>0.594800</td>\n","    </tr>\n","    <tr>\n","      <td>11375</td>\n","      <td>0.331500</td>\n","    </tr>\n","    <tr>\n","      <td>11400</td>\n","      <td>0.572700</td>\n","    </tr>\n","    <tr>\n","      <td>11425</td>\n","      <td>0.397500</td>\n","    </tr>\n","    <tr>\n","      <td>11450</td>\n","      <td>0.603400</td>\n","    </tr>\n","    <tr>\n","      <td>11475</td>\n","      <td>0.351800</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.615100</td>\n","    </tr>\n","    <tr>\n","      <td>11525</td>\n","      <td>0.359700</td>\n","    </tr>\n","    <tr>\n","      <td>11550</td>\n","      <td>0.644800</td>\n","    </tr>\n","    <tr>\n","      <td>11575</td>\n","      <td>0.361800</td>\n","    </tr>\n","    <tr>\n","      <td>11600</td>\n","      <td>0.594200</td>\n","    </tr>\n","    <tr>\n","      <td>11625</td>\n","      <td>0.308600</td>\n","    </tr>\n","    <tr>\n","      <td>11650</td>\n","      <td>0.615800</td>\n","    </tr>\n","    <tr>\n","      <td>11675</td>\n","      <td>0.352200</td>\n","    </tr>\n","    <tr>\n","      <td>11700</td>\n","      <td>0.608900</td>\n","    </tr>\n","    <tr>\n","      <td>11725</td>\n","      <td>0.381400</td>\n","    </tr>\n","    <tr>\n","      <td>11750</td>\n","      <td>0.608300</td>\n","    </tr>\n","    <tr>\n","      <td>11775</td>\n","      <td>0.358800</td>\n","    </tr>\n","    <tr>\n","      <td>11800</td>\n","      <td>0.586400</td>\n","    </tr>\n","    <tr>\n","      <td>11825</td>\n","      <td>0.329000</td>\n","    </tr>\n","    <tr>\n","      <td>11850</td>\n","      <td>0.605000</td>\n","    </tr>\n","    <tr>\n","      <td>11875</td>\n","      <td>0.360400</td>\n","    </tr>\n","    <tr>\n","      <td>11900</td>\n","      <td>0.592000</td>\n","    </tr>\n","    <tr>\n","      <td>11925</td>\n","      <td>0.384400</td>\n","    </tr>\n","    <tr>\n","      <td>11950</td>\n","      <td>0.600400</td>\n","    </tr>\n","    <tr>\n","      <td>11975</td>\n","      <td>0.362500</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.595900</td>\n","    </tr>\n","    <tr>\n","      <td>12025</td>\n","      <td>0.314300</td>\n","    </tr>\n","    <tr>\n","      <td>12050</td>\n","      <td>0.601900</td>\n","    </tr>\n","    <tr>\n","      <td>12075</td>\n","      <td>0.318300</td>\n","    </tr>\n","    <tr>\n","      <td>12100</td>\n","      <td>0.619100</td>\n","    </tr>\n","    <tr>\n","      <td>12125</td>\n","      <td>0.402200</td>\n","    </tr>\n","    <tr>\n","      <td>12150</td>\n","      <td>0.602500</td>\n","    </tr>\n","    <tr>\n","      <td>12175</td>\n","      <td>0.378000</td>\n","    </tr>\n","    <tr>\n","      <td>12200</td>\n","      <td>0.582700</td>\n","    </tr>\n","    <tr>\n","      <td>12225</td>\n","      <td>0.350000</td>\n","    </tr>\n","    <tr>\n","      <td>12250</td>\n","      <td>0.596400</td>\n","    </tr>\n","    <tr>\n","      <td>12275</td>\n","      <td>0.315500</td>\n","    </tr>\n","    <tr>\n","      <td>12300</td>\n","      <td>0.621400</td>\n","    </tr>\n","    <tr>\n","      <td>12325</td>\n","      <td>0.405600</td>\n","    </tr>\n","    <tr>\n","      <td>12350</td>\n","      <td>0.607500</td>\n","    </tr>\n","    <tr>\n","      <td>12375</td>\n","      <td>0.369300</td>\n","    </tr>\n","    <tr>\n","      <td>12400</td>\n","      <td>0.606100</td>\n","    </tr>\n","    <tr>\n","      <td>12425</td>\n","      <td>0.384600</td>\n","    </tr>\n","    <tr>\n","      <td>12450</td>\n","      <td>0.568600</td>\n","    </tr>\n","    <tr>\n","      <td>12475</td>\n","      <td>0.395300</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.599700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Load tokenizer and model with QLoRA configuration\n","compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=use_4bit,\n","    bnb_4bit_quant_type=bnb_4bit_quant_type,\n","    bnb_4bit_compute_dtype=compute_dtype,\n","    bnb_4bit_use_double_quant=use_nested_quant,\n",")\n","\n","# Check GPU compatibility with bfloat16\n","if compute_dtype == torch.float16 and use_4bit:\n","    major, _ = torch.cuda.get_device_capability()\n","    if major >= 8:\n","        print(\"=\" * 80)\n","        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n","        print(\"=\" * 80)\n","\n","# Load base model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=device_map\n",")\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","# Load LLaMA tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n","\n","# Load LoRA configuration\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    r=lora_r,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","# Set training parameters\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    num_train_epochs= 2,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    save_steps=save_steps,\n","    logging_steps=logging_steps,\n","    learning_rate=learning_rate,\n","    weight_decay=weight_decay,\n","    fp16=fp16,\n","    bf16=bf16,\n","    max_grad_norm=max_grad_norm,\n","    max_steps=max_steps,\n","    warmup_ratio=warmup_ratio,\n","    group_by_length=group_by_length,\n","    lr_scheduler_type=lr_scheduler_type,\n","#     report_to=\"tensorboard\"\n",")\n","\n","# Set supervised fine-tuning parameters\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    peft_config=peft_config,\n","    dataset_text_field=\"inp\",\n","    max_seq_length=max_seq_length,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing=packing,\n",")\n","\n","# Train model\n","trainer.train()\n","\n","# Save trained model\n","trainer.model.save_pretrained(new_model)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T05:16:11.568734Z","iopub.status.busy":"2024-07-22T05:16:11.568074Z","iopub.status.idle":"2024-07-22T05:16:24.214862Z","shell.execute_reply":"2024-07-22T05:16:24.213609Z","shell.execute_reply.started":"2024-07-22T05:16:11.568697Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\n"]}],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T05:17:52.517958Z","iopub.status.busy":"2024-07-22T05:17:52.517324Z","iopub.status.idle":"2024-07-22T05:17:52.545819Z","shell.execute_reply":"2024-07-22T05:17:52.544952Z","shell.execute_reply.started":"2024-07-22T05:17:52.517926Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4aea816473244ddbbfe7a6cef1ad35b","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import login\n","\n","# This will prompt you to enter your Hugging Face API token\n","login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.push_to_hub('text-sql')\n","tokenizer.push_to_hub('text-sql')"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T05:21:02.737085Z","iopub.status.busy":"2024-07-22T05:21:02.736690Z","iopub.status.idle":"2024-07-22T05:21:07.914547Z","shell.execute_reply":"2024-07-22T05:21:07.913422Z","shell.execute_reply.started":"2024-07-22T05:21:02.737055Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ed17bd6ae334c248955316d66c6ece0","version_major":2,"version_minor":0},"text/plain":["adapter_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/Soham7021/text-sql-llm_Lama/commit/25936f41f1d8d5bcaddf32cce1c040c8380bacae', commit_message='Upload folder using huggingface_hub', commit_description='', oid='25936f41f1d8d5bcaddf32cce1c040c8380bacae', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["from huggingface_hub import HfApi\n","api = HfApi()\n","\n","# Replace 'your-username' with your actual username on Hugging Face\n","repo_name = 'text-sql-llm_Lama'\n","username = 'Soham7021'\n","\n","api.create_repo(repo_id=f\"{username}/{repo_name}\", repo_type=\"model\")\n","\n","# Upload the saved model and tokenizer to the newly created repository\n","api.upload_folder(\n","    folder_path='./llama-2-7b-text-sql', \n","    path_in_repo='', \n","    repo_id=f'{username}/{repo_name}', \n","    repo_type='model'\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T05:30:01.435556Z","iopub.status.busy":"2024-07-22T05:30:01.435198Z","iopub.status.idle":"2024-07-22T05:32:51.284126Z","shell.execute_reply":"2024-07-22T05:32:51.283261Z","shell.execute_reply.started":"2024-07-22T05:30:01.435530Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Time taken to run the cell: 169.84 seconds\n"," SELECT T1.Firstname, T1.Lastname, T1.BirthDate, T1.Salary FROM Employees AS T1 JOIN Employees AS T2 ON T1.HireDate = T2.HireDate WHERE T2.HireDate = '17/10/023' ORDER BY T1.Salary DESC LIMIT 1\n"]}],"source":["import time\n","logging.set_verbosity(logging.CRITICAL)\n","q = \"Prompt: write query for getting employee with the highest salary who is hired after 17/10/023\"\n","context = \"\"\"Context: CREATE TABLE Employees (\n","    EmployeeID INT NOT NULL,\n","    FirstName VARCHAR(50),\n","    LastName VARCHAR(50),\n","    BirthDate DATE,\n","    HireDate DATE,\n","    JobTitle VARCHAR(50),\n","    Salary DECIMAL(10, 2),\n","    DepartmentID INT,\n","    PRIMARY KEY (EmployeeID)\n",");\n","\"\"\"\n","start_time = time.time()\n","# Run text generation pipeline with our next model\n","prompt = q + context\n","pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=500)\n","result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(f\"Time taken to run the cell: {elapsed_time:.2f} seconds\")\n","print(result[0]['generated_text'].split('[/INST]')[1].split(';')[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
